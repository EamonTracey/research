{
    "system": [
        "You are a helpful TaskVine coding assistant. Provide strictly the requested code using the ndcctools.taskvine library.",
        "The detailed API description of the ndcctools.taskvine library is below, including all classes, methods, and parameters with descriptions:\nndcctools.taskvine.manager.Manager\n  __init__(self, port, name, shutdown, run_info_path, staging_path, ssl, init_fn, status_display_interval) - Create a new manager.\n    self - Reference to the current manager object.\n    port - The port number to listen on. If zero, then a random port is chosen. A range of possible ports (low, hight) can be also specified instead of a single integer. Default is 9123\n    name - The project name to use.\n    shutdown - Automatically shutdown workers when manager is finished. Disabled by default.\n    run_info_path - Directory to write log (and staging if staging_path not given) files per run. If None, defaults to \"vine-run-info\"\n    staging_path - Directory to write temporary files. Defaults to run_info_path if not given.\n    ssl - A tuple of filenames (ssl_key, ssl_cert) in pem format, or True. If not given, then TSL is not activated. If True, a self-signed temporary key and cert are generated.\n    init_fn - Function applied to the newly created manager at initialization.\n    status_display_interval - Number of seconds between updates to the jupyter status display. None, or less than 1 disables it.\n  name() - Get the project name of the manager.\n  port() - Get the listening port of the manager.\n  using_ssl() - Whether the manager is using ssl to talk to workers.\n  logging_directory() - Get the logs directory of the manager.\n  staging_directory() - Get the staging directory of the manager.\n  library_logging_directory() - Get the library logs directory of the manager.\n  cache_directory() - Get the caching directory of the manager.\n  stats() - Get manager statistics.\n  stats_category(self, category) - Get the task statistics for the given category.\n    self - Reference to the current manager object.\n    category - A category name. For example: s = q.stats_category(\"my_category\") >>> print(s)  The fields in ndcctools.taskvine.manager.Manager.stats can also be individually accessed through this call. For example: >>> print(s.tasks_waiting)\n  status(self, request) - Get manager information as list of dictionaries.\n    self - Reference to the current manager object\n    request - One of: \"manager\", \"tasks\", \"workers\", or \"categories\" For example: import json tasks_info = q.status(\"tasks\")\n  summarize_workers(self) - Get resource statistics of workers connected.\n    self - Reference to the current manager object.\n  update_catalog(self) - Send update to catalog server.\n    self - Reference to the current manager object.\n  set_category_mode(self, category, mode) - Turn on or off first-allocation labeling for a given category.\n    self - Reference to the current manager object.\n    category - A category name. If None, sets the mode by default for newly created categories.\n    mode - One of: \"fixed\" Task fails (default). \"max\" If maximum values are specified for cores, memory, disk, and gpus (e.g. via ndcctools.taskvine.manager.Manager.set_category_resources_max or ndcctools.taskvine.task.Task.set_memory), and one of those resources is exceeded, the task fails. Otherwise it is retried until a large enough worker connects to the manager, using the maximum values specified, and the maximum values so far seen for resources not specified. Use ndcctools.taskvine.task.Task.set_retries to set a limit on the number of times manager attemps to complete the task. \"min waste\" As above, but manager tries allocations to minimize resource waste. \"max throughput\" As above, but manager tries allocations to maximize throughput.\n  set_category_autolabel_resource(self, category, resource, autolabel) - Turn on or off first-allocation labeling for a given category and resource.\n    self - Reference to the current manager object.\n    category - A category name.\n    resource - A resource name.\n    autolabel - True/False for on/off.\n  task_state() - Get current task state.\n  enable_monitoring(self, watchdog, time_series) - Enables resource monitoring for tasks.\n    self - Reference to the current manager object.\n    watchdog - If not 0, kill tasks that exhaust declared resources.\n    time_series - If not 0, generate a time series of resources per task in VINE_RUNTIME_INFO_DIR/vine-logs/time-series/ (WARNING: for long running tasks these files may reach gigabyte sizes. This function is mostly used for debugging.)\n  enable_peer_transfers(self) - Enable P2P worker transfer functionality.\n    self - Reference to the current manager object.\n  disable_peer_transfers(self) - Disable P2P worker transfer functionality.\n    self - Reference to the current manager object.\n  enable_disconnect_slow_workers(self) - Change the project name for the given manager.\n    self - Reference to the current manager object.\n  enable_disconnect_slow_workers_category(self, name, multiplier) - Enable disconnect slow workers functionality for a given manager.\n    self - Reference to the current manager object.\n    name - Name of the category.\n    multiplier - The multiplier of the average task time at which point to disconnect a worker; disabled if less than one (see ndcctools.taskvine.manager.Manager.enable_disconnect_slow_workers)\n  set_draining_by_hostname(self, hostname, drain_mode) - Turn on or off draining mode for workers at hostname.\n    self - Reference to the current manager object.\n    hostname - The hostname the host running the workers.\n    drain_mode - If True, no new tasks are dispatched to workers at hostname, and empty workers are shutdown. Else, workers works as usual.\n  empty(self) - Determine whether there are any known tasks managerd, running, or waiting to be collected.\n    self - Reference to the current manager object.\n  hungry(self) - Determine whether the manager can support more tasks.\n    self - Reference to the current manager object.\n  set_scheduler(self, scheduler) - Set the worker selection scheduler for manager.\n    self - Reference to the current manager object.\n    scheduler - One of the following schedulers to use in assigning a task to a worker. See vine_schedule_t for possible values.\n  set_name(self, name) - Change the project name for the given manager.\n    self - Reference to the current manager object.\n    name - The new project name.\n  set_manager_preferred_connection(self, mode) - Set the preference for using hostname over IP address to connect.\n    self - Reference to the current manager object.\n    mode - An string to indicate using 'by_ip', 'by_hostname' or 'by_apparent_ip'.\n  set_min_task_id(self, minid) - Set the minimum task_id of future submitted tasks.\n    self - Reference to the current manager object.\n    minid - Minimum desired task_id\n  set_priority(self, priority) - Change the project priority for the given manager.\n    self - Reference to the current manager object.\n    priority - An integer that presents the priorty of this manager manager. The higher the value, the higher the priority.\n  tasks_left_count(self, ntasks) - Specify the number of tasks not yet submitted to the manager.\n    self - Reference to the current manager object.\n    ntasks - Number of tasks yet to be submitted.\n  set_catalog_servers(self, catalogs) - Specify the catalog servers the manager should report to.\n    self - Reference to the current manager object.\n    catalogs - The catalog servers given as a comma delimited list of hostnames or hostname:port\n  set_property(m, name, value) - Add a global property to the manager which will be included in periodic reports to the catalog server and other telemetry destinations.\n    m - A manager object\n    name - The name of the property.\n    value - The value of the property.\n  set_runtime_info_path(self, dirname) - Specify a directory to write logs and staging files.\n    self - Reference to the current manager object.\n    dirname - A directory name\n  set_password(self, password) - Add a mandatory password that each worker must present.\n    self - Reference to the current manager object.\n    password - The password.\n  set_password_file(self, file) - Add a mandatory password file that each worker must present.\n    self - Reference to the current manager object.\n    file - Name of the file containing the password.\n  set_resources_max(self, rmd) - Specifies the maximum resources allowed for the default category.\n    self - Reference to the current manager object.\n    rmd - Dictionary indicating maximum values. See ndcctools.taskvine.task.Task.resources_measured for possible fields. For example: >>> # A maximum of 4 cores is found on any worker: >>> q.set_resources_max({'cores': 4}) >>> # A maximum of 8 cores, 1GB of memory, and 10GB disk are found on any worker: >>> q.set_resources_max({'cores': 8, 'memory':  1024, 'disk': 10240})\n  set_resources_min(self, rmd) - Specifies the minimum resources allowed for the default category.\n    self - Reference to the current manager object.\n    rmd - Dictionary indicating minimum values. See ndcctools.taskvine.task.Task.resources_measured for possible fields. For example: >>> # A minimum of 2 cores is found on any worker: >>> q.set_resources_min({'cores': 2}) >>> # A minimum of 4 cores, 512MB of memory, and 1GB disk are found on any worker: >>> q.set_resources_min({'cores': 4, 'memory':  512, 'disk': 1024})\n  set_category_resources_max(self, category, rmd) - Specifies the maximum resources allowed for the given category.\n    self - Reference to the current manager object.\n    category - Name of the category.\n    rmd - Dictionary indicating maximum values. See ndcctools.taskvine.task.Task.resources_measured for possible fields. For example: >>> # A maximum of 4 cores may be used by a task in the category: >>> q.set_category_resources_max(\"my_category\", {'cores': 4}) >>> # A maximum of 8 cores, 1GB of memory, and 10GB may be used by a task: >>> q.set_category_resources_max(\"my_category\", {'cores': 8, 'memory':  1024, 'disk': 10240})\n  set_category_resources_min(self, category, rmd) - Specifies the minimum resources allowed for the given category.\n    self - Reference to the current manager object.\n    category - Name of the category.\n    rmd - Dictionary indicating minimum values. See ndcctools.taskvine.task.Task.resources_measured for possible fields. For example: >>> # A minimum of 2 cores is found on any worker: >>> q.set_category_resources_min(\"my_category\", {'cores': 2}) >>> # A minimum of 4 cores, 512MB of memory, and 1GB disk are found on any worker: >>> q.set_category_resources_min(\"my_category\", {'cores': 4, 'memory':  512, 'disk': 1024})\n  set_category_first_allocation_guess(self, category, rmd) - Specifies the first-allocation guess for the given category.\n    self - Reference to the current manager object.\n    category - Name of the category.\n    rmd - Dictionary indicating maximum values. See ndcctools.taskvine.task.Task.resources_measured for possible fields. For example: >>> # Tasks are first tried with 4 cores: >>> q.set_category_first_allocation_guess(\"my_category\", {'cores': 4}) >>> # Tasks are first tried with 8 cores, 1GB of memory, and 10GB: >>> q.set_category_first_allocation_guess(\"my_category\", {'cores': 8, 'memory':  1024, 'disk': 10240})\n  set_category_max_concurrent(self, category, max_concurrent) - Specifies the maximum resources allowed for the given category.\n    self - Reference to the current work queue object.\n    category - Name of the category.\n    max_concurrent - Number of maximum concurrent tasks. Less then 0 means unlimited (this is the default). For example: >>> # Do not run more than 5 tasks of \"my_category\" concurrently: >>> q.set_category_max_concurrent(\"my_category\", 5)\n  initialize_categories(self, rm, filename) - Initialize first value of categories.\n    self - Reference to the current manager object.\n    rm - Dictionary indicating maximum values. See ndcctools.taskvine.task.Task.resources_measured for possible fields.\n    filename - JSON file with resource summaries.\n  cancel_by_task_id(self, id) - Cancel task identified by its task_id.\n    self - Reference to the current manager object.\n    id - The task_id returned from ndcctools.taskvine.manager.Manager.submit.\n  cancel_by_task_tag(self, tag) - Cancel task identified by its tag.\n    self - Reference to the current manager object.\n    tag - The tag assigned to task using ndcctools.taskvine.task.Task.set_tag.\n  cancel_by_category(self, category) - Cancel all tasks of the given category.\n    self - Reference to the current manager object.\n    category - The name of the category to cancel.\n  cancel_all(self) - Cancel all tasks.\n    self - Reference to the current manager object.\n  workers_shutdown(self, n) - Shutdown workers connected to manager.\n    self - Reference to the current manager object.\n    n - The number to shutdown. 0 shutdowns all workers\n  block_host(self, host) - Block workers running on host from working for the manager.\n    self - Reference to the current manager object.\n    host - The hostname the host running the workers.\n  blacklist() - Replaced by ndcctools.taskvine.manager.Manager.block_host.\n  block_host_with_timeout(self, host, timeout) - Block workers running on host for the duration of the given timeout.\n    self - Reference to the current manager object.\n    host - The hostname the host running the workers.\n    timeout - How long this block entry lasts (in seconds). If less than 1, block indefinitely.\n  blacklist_with_timeout() - See ndcctools.taskvine.manager.Manager.block_host_with_timeout.\n  unblock_host(self, host) - Unblock given host, of all hosts if host not given.\n    self - Reference to the current manager object.\n    host - The of the hostname the host.\n  blacklist_clear() - See ndcctools.taskvine.manager.Manager.unblock_host.\n  set_keepalive_interval(self, interval) - Change keepalive interval for a given manager.\n    self - Reference to the current manager object.\n    interval - Minimum number of seconds to wait before sending new keepalive checks to workers.\n  set_keepalive_timeout(self, timeout) - Change keepalive timeout for a given manager.\n    self - Reference to the current manager object.\n    timeout - Minimum number of seconds to wait for a keepalive response from worker before marking it as dead.\n  tune(self, name, value) - Tune advanced parameters.\n    self - Reference to the current manager object.\n    name - The name fo the parameter to tune. Can be one of following: \"attempt-schedule-depth\" The amount of tasks to attempt scheduling on each pass of send_one_task in the main loop. (default=100) \"category-steady-n-tasks\" Set the number of tasks considered when computing category buckets. \"default-transfer-rate\" The assumed network bandwidth used until sufficient data has been collected. (1MB/s) \"disconnect-slow-workers-factor\" Set the multiplier of the average task time at which point to disconnect a worker; disabled if less than 1. (default=0) \"hungry-minimum\" Mimimum number of tasks to consider manager not hungry. (default=10) \"hungry-minimum-factor\" Queue is hungry if number of waiting tasks is less than hungry-minumum-factor x (number of workers) | 2 | \"immediate-recovery\" If set to 1, create recovery tasks for temporary files as soon as their worker disconnects. Otherwise, create recovery tasks only if the temporary files are used as input when trying to dispatch another task. \"keepalive-interval\" Set the minimum number of seconds to wait before sending new keepalive checks to workers. (default=300) \"keepalive-timeout\" Set the minimum number of seconds to wait for a keepalive response from worker before marking it as dead. (default=30) \"long-timeout\" Set the minimum timeout in seconds when sending a large message to a single worker. (default=3600) \"max-retrievals\" Sets the max number of tasks to retrieve per manager wait(). If less than 1, the manager prefers to retrieve all completed tasks before dispatching new tasks to workers. (default=1) \"min-transfer-timeout\" Set the minimum number of seconds to wait for files to be transferred to or from a worker. (default=10) \"monitor-interval\" Parameter to change how frequently the resource monitor records resource consumption of a task in a times series, if this feature is enabled. See enable_monitoring. \"prefer-dispatch\" If 1, try to dispatch tasks even if there are retrieved tasks ready to be reported as done. (default=0) \"proportional-resources\" If set to 0, do not assign resources proportionally to tasks. The default is to use proportions. \"proportional-whole-tasks\" Round up resource proportions such that only an integer number of tasks could be fit in the worker. The default is to use proportions. \"ramp-down-heuristic\" If set to 1 and there are more workers than tasks waiting, then tasks are allocated all the free resources of a worker large enough to run them. If monitoring watchdog is not enabled, then this heuristic has no effect. (default=0) \"resource-submit-multiplier\" Treat each worker as having ({cores,memory,gpus} * multiplier) when submitting tasks. This allows for tasks to wait at a worker rather than the manager. (default = 1.0) \"short-timeout\" Set the minimum timeout when sending a brief message to a single worker. (default=5s) \"transfer-outlier-factor\" Transfer that are this many times slower than the average will be terminated. (default=10x) \"transfer-replica-per-cycle\" Number of replicas to schedule per file per iteration. (default=1) \"transfer-temps-recovery\" If 1, try to replicate temp files to reach threshold on worker removal. (default=0) \"transient-error-interval\" Time to wait in seconds after a resource failure before attempting to use it again. (default=15) \"wait-for-workers\" Mimimum number of workers to connect before starting dispatching tasks. (default=0) \"wait-retrieve-many\" If set to 0, cvine.vine_wait breaks out of the while loop whenever a task changes to \"task_done\" (wait_retrieve_one mode). If set to 1, vine_wait does not break, but continues recieving and dispatching tasks. This occurs until no task is sent or recieved, at which case it breaks out of the while loop (wait_retrieve_many mode). (default=0) \"worker-retrievals\" If 1, retrieve all completed tasks from a worker when retrieving results, even if going above the parameter max-retrievals . Otherwise, if 0, retrieve just one task before deciding to dispatch new tasks or connect new workers. (default=1) \"watch-library-logfiles\" If 1, watch the output files produced by each of the library processes running on the remote workers, take them back the current logging directory. (default=0)\n    value - The value to set the parameter to.\n  submit(self, task) - Submit a task to the manager.\n    self - Reference to the current manager object.\n    task - A task description created from ndcctools.taskvine.task.Task.\n  install_library(self, task) - Submit a library to install on all connected workers.\n    self - Reference to the current manager object.\n    task - A Library Task description created from create_library_from_functions or create_library_from_files\n  remove_library(self, name) - Remove a library from all connected workers.\n    self - Reference to the current manager object.\n    name - Name of the library to be removed.\n  check_library_exists(self, library_name) - Check whether a libray exists on the manager or not.\n    self - Reference to the current manager object.\n    library_name - Name of the library to be checked\n  create_library_from_functions(self, library_name, function_list, poncho_env, init_command, add_env, hoisting_modules, exec_mode, library_context_info) - Turn a list of python functions into a Library Task.\n    self - Reference to the current manager object.\n    library_name - Name of the Library to be created\n    function_list - List of all functions to be included in the library\n    poncho_env - Name of an already prepared poncho environment or a conda environment\n    init_command - A string describing a shell command to execute before the library task is run\n    add_env - Whether to automatically create and/or add environment to the library\n    hoisting_modules - A list of modules imported at the preamble of library, including packages, functions and classes.\n    exec_mode - Execution mode that the library should use to run function calls. Either 'direct' or 'fork'\n    library_context_info - A list containing [library_context_func, library_context_args, library_context_kwargs]. Used to create the library context on remote nodes.\n  create_library_from_serverized_files(self, library_name, library_path, env) - Turn Library code created with poncho_package_serverize into a Library Task.\n    self - Reference to the current manager object.\n    library_name - Name that identifies this library to the FunctionCalls\n    library_path - Filename of the library (i.e., the output of poncho_package_serverize)\n    env - Environment to run the library. Either a vine file that expands to an environment (see ndcctools.taskvine.task.Task.add_environment), or a path to a poncho environment.\n  create_library_from_command(self, executable_path, name, env) - Create a Library task from arbitrary inputs.\n    self - Reference to the current manager object\n    executable_path - Filename of the library executable\n    name - Name of the library to be created\n    env - Environment to run the library. Either a vine file that expands to an environment (see ndcctools.taskvine.task.Task.add_environment), or a path to a poncho environment.\n  wait(self, timeout) - Wait for tasks to complete.\n    self - Reference to the current manager object.\n    timeout - The number of seconds to wait for a completed task before returning. Use an integer to set the timeout or the value \"wait_forever\" to block until a task has completed. If 0, return immediately with a complete task if one available, or None otherwise.\n  wait_for_tag(self, tag, timeout) - Similar to ndcctools.taskvine.manager.Manager.wait, but guarantees that the returned task has the specified tag.\n    self - Reference to the current manager object.\n    tag - Desired tag. If None, then it is equivalent to self.wait(timeout)\n    timeout - The number of seconds to wait for a completed task before returning. If 0, return immediately with a complete task if one available, or None otherwise.\n  wait_for_task_id(self, task_id, timeout) - Similar to ndcctools.taskvine.manager.Manager.wait, but guarantees that the returned task has the specified task_id.\n    self - Reference to the current manager object.\n    task_id - Desired task_id. If -1, then it is equivalent to self.wait(timeout)\n    timeout - The number of seconds to wait for a completed task before returning. If 0, return immediately with a complete task if one available, or None otherwise.\n  application_info(self) - Should return a dictionary with information for the status display.\n    self - Reference to the current work queue object.\n  map(self, fn, seq, chunksize) - Maps a function to elements in a sequence using taskvine.\n    self - Reference to the current manager object.\n    fn - The function that will be called on each element\n    seq - The sequence that will call the function\n    chunksize - The number of elements to process at once\n  pair(self, fn, seq1, seq2, chunksize, env) - Returns the values for a function of each pair from 2 sequences.\n    self - Reference to the current manager object.\n    fn - The function that will be called on each element\n    seq1 - The first seq that will be used to generate pairs\n    seq2 - The second seq that will be used to generate pairs\n    chunksize - Number of pairs to process at once (default is 1)\n    env - Filename of a python environment tarball (conda or poncho)\n  tree_reduce(self, fn, seq, chunksize) - Reduces a sequence until only one value is left, and then returns that value.\n    self - Reference to the current manager object.\n    fn - The function that will be called on each element\n    seq - The seq that will be reduced\n    chunksize - The number of elements per Task (for tree reduc, must be greater than 1)\n  remote_map(self, fn, seq, library, name, chunksize) - Maps a function to elements in a sequence using taskvine remote task.\n    self - Reference to the current manager object.\n    fn - The function that will be called on each element. This function exists in library.\n    seq - The sequence that will call the function\n    library - The name of the library that contains the function fn.\n    name - This defines the key in the event json that wraps the data sent to the library.\n    chunksize - The number of elements to process at once\n  remote_pair(self, fn, seq1, seq2, library, name, chunksize) - Returns the values for a function of each pair from 2 sequences using remote task.\n    self - Reference to the current manager object.\n    fn - The function that will be called on each element. This function exists in library.\n    seq1 - The first seq that will be used to generate pairs\n    seq2 - The second seq that will be used to generate pairs\n    library - The name of the library that contains the function fn.\n    name - This defines the key in the event json that wraps the data sent to the library.\n    chunksize - The number of elements to process at once\n  remote_tree_reduce(self, fn, seq, library, name, chunksize) - Reduces a sequence until only one value is left, and then returns that value.\n    self - Reference to the current manager object.\n    fn - The function that will be called on each element. Exists on the library\n    seq - The seq that will be reduced\n    library - The name of the library that contains the function fn.\n    name - This defines the key in the event json that wraps the data sent to the library.\n    chunksize - The number of elements per Task (for tree reduc, must be greater than 1)\n  declare_file(self, path, cache, peer_transfer, unlink_when_done) - Declare a file obtained from the local filesystem.\n    self - The manager to register this file\n    path - The path to the local file\n    cache - If True or 'workflow', cache the file at workers for reuse until the end of the workflow. If 'worker', the file is cache until the end-of-life of the worker. If 'forever', the file is cached beyond the end-of-life of the worker. Default is False (file is not cached).\n    peer_transfer - Whether the file can be transfered between workers when peer transfers are enabled (see ndcctools.taskvine.manager.Manager.enable_peer_transfers). Default is True.\n    unlink_when_done - Whether to delete the file when its reference count is 0. (Warning: Only use on files produced by the application, and never on irreplaceable input files.)\n  fetch_file(self, file) - Fetch file contents from the cluster or local disk.\n    self - The manager to register this file\n    file - The file object\n  undeclare_file(self, file) - Un-declare a file that was created by declare_file or similar methods.\n    self - The manager to register this file\n    file - The file object\n  undeclare_function(self, fn) - Remove the manager's local serialized copy of a function used with PythonTask.\n    self - The manager to register this file\n    fn - The function that the manager should forget.\n  declare_temp(self) - Declare an anonymous file has no initial content, but is created as the output of a task, and may be consumed by other tasks.\n    self - The manager to register this file\n  declare_url(self, url, cache, peer_transfer) - Declare a file obtained from a remote URL.\n    self - The manager to register this file\n    url - The url of the file.\n    cache - If True or 'workflow', cache the file at workers for reuse until the end of the workflow. If 'worker', the file is cache until the end-of-life of the worker. If 'forever', the file is cached beyond the end-of-life of the worker. Default is False (file is not cached).\n    peer_transfer - Whether the file can be transfered between workers when peer transfers are enabled (see ndcctools.taskvine.manager.Manager.enable_peer_transfers). Default is True.\n  declare_buffer(self, buffer, cache, peer_transfer) - Declare a file created from a buffer in memory.\n    self - The manager to register this file\n    buffer - The contents of the buffer, or None for an empty output buffer\n    cache - If True or 'workflow', cache the file at workers for reuse until the end of the workflow. If 'worker', the file is cache until the end-of-life of the worker. If 'forever', the file is cached beyond the end-of-life of the worker. Default is False (file is not cached).\n    peer_transfer - Whether the file can be transfered between workers when peer transfers are enabled (see ndcctools.taskvine.manager.Manager.enable_peer_transfers). Default is True.\n  declare_minitask(self, minitask, source, cache, peer_transfer) - Declare a file created by executing a mini-task.\n    self - The manager to register this file\n    minitask - The task to execute in order to produce a file\n    source - The name of the file to extract from the task's sandbox.\n    cache - If True or 'workflow', cache the file at workers for reuse until the end of the workflow. If 'worker', the file is cache until the end-of-life of the worker. If 'forever', the file is cached beyond the end-of-life of the worker. Default is False (file is not cached).\n    peer_transfer - Whether the file can be transfered between workers when peer transfers are enabled (see ndcctools.taskvine.manager.Manager.enable_peer_transfers). Default is True.\n  declare_untar(self, tarball, cache, peer_transfer) - Declare a file created by by unpacking a tar file.\n    self - The manager to register this file\n    tarball - The file object to un-tar\n    cache - If True or 'workflow', cache the file at workers for reuse until the end of the workflow. If 'worker', the file is cache until the end-of-life of the worker. If 'forever', the file is cached beyond the end-of-life of the worker. Default is False (file is not cached).\n    peer_transfer - Whether the file can be transfered between workers when peer transfers are enabled (see ndcctools.taskvine.manager.Manager.enable_peer_transfers). Default is True.\n  declare_poncho(self, package, cache, peer_transfer) - Declare a file that sets up a poncho environment.\n    self - The manager to register this file\n    package - The poncho environment tarball. Either a vine file or a string representing a local file.\n    cache - If True or 'workflow', cache the file at workers for reuse until the end of the workflow. If 'worker', the file is cache until the end-of-life of the worker. If 'forever', the file is cached beyond the end-of-life of the worker. Default is False (file is not cached).\n    peer_transfer - Whether the file can be transfered between workers when peer transfers are enabled (see ndcctools.taskvine.manager.Manager.enable_peer_transfers). Default is True.\n  declare_starch(self, starch, cache, peer_transfer) - Declare a file create a file by unpacking a starch package.\n    self - The manager to register this file\n    starch - The startch .sfx file. Either a vine file or a string representing a local file.\n    cache - If True or 'workflow', cache the file at workers for reuse until the end of the workflow. If 'worker', the file is cache until the end-of-life of the worker. If 'forever', the file is cached beyond the end-of-life of the worker. Default is False (file is not cached).\n    peer_transfer - Whether the file can be transfered between workers when peer transfers are enabled (see ndcctools.taskvine.manager.Manager.enable_peer_transfers). Default is True.\n  declare_xrootd(self, source, proxy, env, cache, peer_transfer) - Declare a file from accessible from an xrootd server.\n    self - The manager to register this file.\n    source - The URL address of the root file in text form as: \"root://XROOTSERVER[:port]//path/to/file\"\n    proxy - A ndcctools.taskvine.file.File of the X509 proxy to use. If None, the environment variable X509_USER_PROXY and the file \"$TMPDIR/$UID\" are considered in that order. If no proxy is present, the transfer is tried without authentication.\n    env - If not None, an environment file (e.g poncho or starch, see ndcctools.taskvine.task.Task.add_environment) that contains the xrootd executables. Otherwise assume xrootd is available at the worker.\n    cache - If True or 'workflow', cache the file at workers for reuse until the end of the workflow. If 'worker', the file is cache until the end-of-life of the worker. If 'forever', the file is cached beyond the end-of-life of the worker. Default is False (file is not cached).\n    peer_transfer - Whether the file can be transfered between workers when peer transfers are enabled (see ndcctools.taskvine.manager.Manager.enable_peer_transfers). Default is True.\n  declare_chirp(self, server, source, ticket, env, cache, peer_transfer) - Declare a file from accessible from an xrootd server.\n    self - The manager to register this file.\n    server - The chirp server address of the form \"hostname[:port\"]\"\n    source - The name of the file in the server\n    ticket - If not None, a file object that provides a chirp an authentication ticket\n    env - If not None, an environment file (e.g poncho or starch) that contains the chirp executables. Otherwise assume chirp is available at the worker.\n    cache - If True or 'workflow', cache the file at workers for reuse until the end of the workflow. If 'worker', the file is cache until the end-of-life of the worker. If 'forever', the file is cached beyond the end-of-life of the worker. Default is False (file is not cached).\n    peer_transfer - Whether the file can be transfered between workers when peer transfers are enabled (see ndcctools.taskvine.manager.Manager.enable_peer_transfers). Default is True.\n  log_txn_app(self, server) - Adds a custom APPLICATION entry to the transactions log.\n    self - The manager to register this file.\n    server - A custom transaction message\n  log_debug_app(self, server) - Adds a custom APPLICATION entry to the debug log.\n    self - The manager to register this file.\n    server - A custom debug message\nndcctools.taskvine.task.Task\n  __init__(self, command, task_info) - Create a new task specification.\n    self - Reference to the current task object.\n    command - The shell command line to be exected by the task.\n    task_info - Optional dictionary containing specified task parameters.\n  submit_finalize(self) - Finalizes the task definition once the manager that will execute is run.\n    self - Reference to the current python task object\n  clone() - Return a copy of this task.\n  set_command(self, command) - Set the command to be executed by the task.\n    self - Reference to the current task object.\n    command - The command to be executed.\n  set_library_required(self, library) - Set the name of the library at the worker that should execute the task's command.\n    self - Reference to the current task object.\n    library - The library or the name of the library\n  get_library_required(self) - Get the name of the library at the worker that should execute the task's command.\n    self - Reference to the current task object.\n  needs_library() - Deprecated, see set_library_required.\n  set_library_provided(self, library_name) - Set the library name provided by this task.\n    self - Reference to the current task object.\n    library_name - The name of the library.\n  get_libray_provided(self) - Get the name of the library at the worker that should execute the task's command.\n    self - Reference to the current task object.\n  provides_library() - Deprecated, see set_library_provided.\n  set_function_slots(self, nslots) - Set the number of concurrent functions a library can run.\n    self - Reference to the current task object.\n    nslots - The maximum number of concurrent functions this library can run.\n  set_function_exec_mode_from_string(self, exec_mode) - Set the execution mode of functions in a library.\n    self - Reference to the current task object.\n    exec_mode - The execution mode of functions in a library. Either 'fork' or 'direct'.\n  set_scheduler(self, scheduler) - Set the worker selection scheduler for task.\n    self - Reference to the current task object.\n    scheduler - One of the following schedulers to use in assigning a task to a worker. See vine_schedule_t for possible values.\n  set_tag(self, tag) - Attach a user defined logical name to the task.\n    self - Reference to the current task object.\n    tag - The tag to attach to task.\n  set_category(self, name) - Label the task with the given category.\n    self - Reference to the current task object.\n    name - The name of the category\n  add_feature(self, name) - Label the task with the given user-defined feature.\n    self - Reference to the current task object.\n    name - The name of the feature.\n  add_input(self, file, remote_name, strict_input) - Add any input object to a task.\n    self - Reference to the current task object.\n    file - A file object of class ndcctools.taskvine.file.File, such as from ndcctools.taskvine.manager.Manager.declare_file, ndcctools.taskvine.manager.Manager.declare_buffer, ndcctools.taskvine.manager.Manager.declare_url, etc.\n    remote_name - The name of the file at the execution site.\n    strict_input - Whether the file should be transfered to the worker for execution. If no worker has all the input files already cached marked as strict inputs for the task, the task fails.\n  add_output(self, file, remote_name, watch, success_only, failure_only) - Add any output object to a task.\n    self - Reference to the current task object.\n    file - A file object of class ndcctools.taskvine.file.File, such as from ndcctools.taskvine.manager.Manager.declare_file, or ndcctools.taskvine.manager.Manager.declare_buffer ndcctools.taskvine.task.Task.add_input\n    remote_name - The name of the file at the execution site.\n    watch - Watch the output file and send back changes as the task runs.\n    success_only - Whether the file should be retrieved only when the task succeeds. Default is False.\n    failure_only - Whether the file should be retrieved only when the task fails (e.g., debug logs). Default is False.\n  set_snapshot_file(self, filename) - When monitoring, indicates a json-encoded file that instructs the monitor to take a snapshot of the task resources.\n    self - Reference to the current task object.\n    filename - The name of the snapshot events specification\n  add_starch_package(t, f) - Add a Starch package as an execution context.\n    t - A task object.\n    f - A file containing an unpacked Starch package.\n  add_poncho_package(t, f) - Add a Poncho package as an execution context.\n    t - A task object.\n    f - A file containing an unpacked Poncho package.\n  add_execution_context(t, f) - Adds an execution context to the task.\n    t - A task object.\n    f - The execution context file.\n  set_retries() - Indicate the number of times the task should be retried.\n  set_max_forsaken() - Indicate the number of times the task can be returned to the manager without being executed.\n  set_cores() - Indicate the number of cores required by this task.\n  set_memory() - Indicate the memory (in MB) required by this task.\n  set_disk() - Indicate the disk space (in MB) required by this task.\n  set_gpus() - Indicate the number of GPUs required by this task.\n  set_priority() - Indicate the the priority of this task (larger means better priority, default is 0).\n  set_env_var() - Set this environment variable before running the task.\n  set_monitor_output() - Set a name for the resource summary output directory from the monitor.\n  tag() - Get the user-defined logical name for the task.\n  category() - Get the category name for the task.\n  command() - Get the shell command executed by the task.\n  state() - Get the state of the task.\n  std_output() - Get the standard output of the task.\n  output() - Get the standard output of the task.\n  id() - Get the task id number.\n  exit_code() - Get the exit code of the command executed by the task.\n  result() - Return a string that explains the result of a task.\n  completed() - Return True if task executed and its command terminated normally.\n  successful() - Return True if task executed successfully, (i.e.\n  get_metric() - Return various integer performance metrics about a completed task.\n  addrport() - Get the address and port of the host on which the task ran.\n  hostname() - Get the address and port of the host on which the task ran.\n  resources_measured() - Get the resources measured for the task execution if resource monitoring is enabled.\n  limits_exceeded() - Get the resources the task exceeded.\n  resources_requested() - Get the resources the task requested to run.\n  resources_allocated() - Get the resources allocated to the task in its latest attempt.\n  add_nopen() - Adds inputs for nopen library and rules file and sets LD_PRELOAD.\nndcctools.taskvine.task.LibraryTask\n  __init__(self, fn, library_name) - Create a new LibraryTask task specification.\n    self - Reference to the current remote task object.\n    fn - The command for this LibraryTask to run\n    library_name - The name of this Library.\nndcctools.taskvine.task.PythonTask\n  __init__(self, func, args, kwargs) - Creates a new python task.\n    self - Reference to the current python task object\n    func - python function to be executed by task\n    args - arguments used in function to be executed by task\n    kwargs - keyword arguments used in function to be executed by task\n  submit_finalize(self, manager) - Finalizes the task definition once the manager that will execute is run.\n    self - Reference to the current python task object\n    manager - Manager to which the task was submitted\n  enable_temp_output(self) - Marks the output of this task to stay at the worker.\n    self - Reference to the current python task object\n  set_output_cache(cache) - Set the cache behavior for the output of the task.\n    cache - If True or 'workflow', cache the file at workers for reuse until the end of the workflow. If 'always', the file is cache until the end-of-life of the worker. Default is False (file is not cache).\n  output_file() - Returns the ndcctools.taskvine.file.File object that represents the output of this task.\n  output(self) - returns the result of a python task as a python variable\n    self - reference to the current python task object\n  disable_output_serialization(self) - Disables serialization of results to disk when writing to a file for transmission.\n    self - Reference to the current python task object\nndcctools.taskvine.task.FunctionCall\n  __init__(self, library, fn, args, kwargs) - Create a new FunctionCall specification.\n    self - Reference to the current FunctionCall object.\n    library - The library, or name of the library which has the function you wish to execute.\n    fn - The name of the function to be executed on the library.\n    args - positional arguments used in function to be executed by task. Can be mixed with kwargs\n    kwargs - keyword arguments used in function to be executed by task.\n  submit_finalize(self) - Finalizes the task definition once the manager that will execute is run.\n    self - Reference to the current python task object\n  set_fn_args(self, args, kwargs) - Specify function arguments.\n    self - Reference to the current remote task object\n    args - An array of positional args to be passed to the function\n    kwargs - A dictionary of keyword arguments to be passed to the function\n  set_exec_method(self, remote_task_exec_method) - Specify how the remote task should execute.\n    self - Reference to the current remote task object\n    remote_task_exec_method - Can be either of \"fork\" or \"direct\". Fork creates a child process to execute the function and direct has the worker directly call the function.\n  output() - Retrieve output, handles cleanup, and returns result or failure reason.\n"
    ],
    "prompts": [
        {
            "id": "taskvine0",
            "content": "Write a Python TaskVine application to get the current date on a worker machine. The date must be stored to an output file named \"current_date\".",
            "response": "```python\nfrom ndcctools.taskvine.manager import Manager\nfrom ndcctools.taskvine.task import Task\n\n# Create a manager\nmanager = Manager(port=9123, name=\"date_project\", shutdown=True, run_info_path=None, staging_path=None, ssl=None, init_fn=None, status_display_interval=None)\n\n# Create a task to get the current date\ntask = Task(command=\"date > current_date\", task_info={})\n\n# Submit the task to the manager\nmanager.submit(task)\n\n# Wait for the task to complete\ncompleted_task = manager.wait(timeout=\"wait_forever\")\n\n# Check if the task completed successfully\nif completed_task and completed_task.successful():\n    print(\"Task completed successfully. The current date is stored in 'current_date'.\")\nelse:\n    print(\"Task failed.\")\n```"
        },
        {
            "id": "taskvine1",
            "content": "Write a Python TaskVine application to count the number of times the keywords \"wealth\", \"nation\", \"labour\", \"price\", \"nature\", and \"commodity\" appear in Adam Smith's Wealth of Nations. The text is available at \"https://www.gutenberg.org/cache/epub/3300/pg3300.txt\".",
            "response": "```python\nimport ndcctools.taskvine as vine\nimport requests\n\n# Define the keywords to search for\nkeywords = [\"wealth\", \"nation\", \"labour\", \"price\", \"nature\", \"commodity\"]\n\n# Function to count keywords in the text\ndef count_keywords(text, keywords):\n    counts = {keyword: text.lower().count(keyword) for keyword in keywords}\n    return counts\n\n# Download the text of \"Wealth of Nations\"\nurl = \"https://www.gutenberg.org/cache/epub/3300/pg3300.txt\"\nresponse = requests.get(url)\ntext = response.text\n\n# Create a TaskVine manager\nmanager = vine.Manager(port=9123, name=\"WealthOfNations\", shutdown=True, run_info_path=None, staging_path=None, ssl=None, init_fn=None, status_display_interval=None)\n\n# Create a PythonTask to count the keywords\ntask = vine.task.PythonTask(func=count_keywords, args=(text, keywords), kwargs={})\n\n# Submit the task to the manager\nmanager.submit(task)\n\n# Wait for the task to complete and get the result\ncompleted_task = manager.wait(timeout=\"wait_forever\")\nif completed_task:\n    result = completed_task.output()\n    print(\"Keyword counts in 'Wealth of Nations':\")\n    for keyword, count in result.items():\n        print(f\"{keyword}: {count}\")\nelse:\n    print(\"Task did not complete.\")\n```\n\nThis script uses TaskVine to count the occurrences of specified keywords in the text of \"Wealth of Nations\". It downloads the text, defines a function to count the keywords, and submits this function as a task to the TaskVine manager. The result is printed once the task is completed."
        },
        {
            "id": "taskvine2",
            "content": "Write a Python TaskVine application to run my program \"script.sh\" with various input arguments and organizes all output data. \"script.sh\" takes, as input, an integer and two files. \"script.sh\" outputs a file named \"output{i}.txt\" where \"{i}\" is the input integer. The application must run \"script.sh\" with input integers 1-1000 and input files \"file1.input\" and \"file2.input\" which are stored in the directory \"script_inputs\". The application must store all output files in a directory named \"script_outputs\".",
            "response": "```python\nimport os\nfrom ndcctools.taskvine.manager import Manager\nfrom ndcctools.taskvine.task import Task\n\n# Create directories for inputs and outputs\ninput_dir = \"script_inputs\"\noutput_dir = \"script_outputs\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Initialize the TaskVine manager\nmanager = Manager(port=9123, name=\"script_manager\", shutdown=True, run_info_path=None, staging_path=None, ssl=None, init_fn=None, status_display_interval=None)\n\n# Declare input files\nfile1 = manager.declare_file(os.path.join(input_dir, \"file1.input\"), cache=True, peer_transfer=True, unlink_when_done=False)\nfile2 = manager.declare_file(os.path.join(input_dir, \"file2.input\"), cache=True, peer_transfer=True, unlink_when_done=False)\n\n# Submit tasks\nfor i in range(1, 1001):\n    task = Task(command=f\"./script.sh {i} file1.input file2.input\")\n    task.add_input(file1, \"file1.input\", strict_input=True)\n    task.add_input(file2, \"file2.input\", strict_input=True)\n    \n    output_file_path = os.path.join(output_dir, f\"output{i}.txt\")\n    output_file = manager.declare_file(output_file_path, cache=False, peer_transfer=False, unlink_when_done=False)\n    task.add_output(output_file, f\"output{i}.txt\", watch=False, success_only=True, failure_only=False)\n    \n    manager.submit(task)\n\n# Wait for all tasks to complete\nwhile not manager.empty():\n    completed_task = manager.wait(5)\n    if completed_task:\n        if completed_task.successful():\n            print(f\"Task {completed_task.id()} completed successfully.\")\n        else:\n            print(f\"Task {completed_task.id()} failed with exit code {completed_task.exit_code()}.\")\n\nprint(\"All tasks have been processed.\")\n```"
        },
        {
            "id": "taskvine3",
            "content": "Write a Python TaskVine application to execute a pipeline of shell scripts. I have the script \"script1.sh\" which outputs a file named \"intermediary.out\" upon completion. I also have the scripts \"script2.sh\" and \"script3.sh\"  which both accept an input file as a command line argument. \"script2.sh\" and \"script3.sh\" must both receive \"intermediary.out\" as the input. Finally, \"script2.sh\" and \"script3.sh\" output files named \"script2.out\" and \"script3.out\", respectively. Save these outputs files on the host machine. \"intermediary.out\" need not be saved to the host machine.",
            "response": "```python\nfrom ndcctools.taskvine.manager import Manager\nfrom ndcctools.taskvine.task import Task\n\n# Create a manager\nmanager = Manager(port=9123, name=\"pipeline\", shutdown=True, run_info_path=None, staging_path=None, ssl=None, init_fn=None, status_display_interval=None)\n\n# Declare the intermediary output file\nintermediary_file = manager.declare_temp()\n\n# Task 1: Execute script1.sh\ntask1 = Task(command=\"./script1.sh\")\ntask1.add_output(intermediary_file, \"intermediary.out\", watch=False, success_only=True, failure_only=False)\n\n# Submit task1\nmanager.submit(task1)\n\n# Task 2: Execute script2.sh with intermediary.out as input\ntask2 = Task(command=\"./script2.sh intermediary.out\")\ntask2.add_input(intermediary_file, \"intermediary.out\", strict_input=True)\ntask2.add_output(\"script2.out\", \"script2.out\", watch=False, success_only=True, failure_only=False)\n\n# Submit task2\nmanager.submit(task2)\n\n# Task 3: Execute script3.sh with intermediary.out as input\ntask3 = Task(command=\"./script3.sh intermediary.out\")\ntask3.add_input(intermediary_file, \"intermediary.out\", strict_input=True)\ntask3.add_output(\"script3.out\", \"script3.out\", watch=False, success_only=True, failure_only=False)\n\n# Submit task3\nmanager.submit(task3)\n\n# Wait for all tasks to complete\nwhile not manager.empty():\n    manager.wait(5)\n\nprint(\"Pipeline execution completed.\")\n```\n\nThis code sets up a TaskVine manager and submits three tasks corresponding to the three scripts. The intermediary output from `script1.sh` is used as input for both `script2.sh` and `script3.sh`. The final outputs `script2.out` and `script3.out` are saved on the host machine."
        },
        {
            "id": "taskvine4",
            "content": "Write a Python TaskVine application to run my GPU-accelerated program. The program binary is stored at \"./train_demo\". The program requires that the worker machine has the feature \"NVIDIA RTX 4090\". Upon completion, the program outputs \"model.tar.gz\". The output file must be saved to the host machine.",
            "response": "```python\nimport ndcctools.taskvine as vine\n\n# Create a manager\nmanager = vine.manager.Manager(port=9123, name=\"gpu_program_manager\", shutdown=True)\n\n# Declare the output file\noutput_file = manager.declare_temp()\n\n# Create a task for the GPU-accelerated program\ntask = vine.task.Task(command=\"./train_demo\")\n\n# Add the required feature for the task\ntask.add_feature(\"NVIDIA RTX 4090\")\n\n# Add the output file to the task\ntask.add_output(file=output_file, remote_name=\"model.tar.gz\", watch=False, success_only=True, failure_only=False)\n\n# Submit the task to the manager\nmanager.submit(task)\n\n# Wait for the task to complete\ncompleted_task = manager.wait(timeout=\"wait_forever\")\n\n# Fetch the output file to the host machine\nif completed_task and completed_task.successful():\n    manager.fetch_file(output_file)\n    print(\"Task completed successfully and output file fetched.\")\nelse:\n    print(\"Task failed or did not complete successfully.\")\n```"
        },
        {
            "id": "taskvine5",
            "content": "Write a Python TaskVine application to compile and test my project stored at \"complex_project/\". To compile the project, run the \"make all\" command in the project's root directory. Then, to test the project, run \"make test\". The compilation and test must use at most 4 cores, 1024 MB of memory, and 2048 MB of disk. Enable resource monitoring to track resource usage, but do not terminate the task if it overuses resources. When the task completes, print the task's exit code and standard output. For each resource that the task overused, print the resource and by how much it overused.",
            "response": "```python\nfrom ndcctools.taskvine.manager import Manager\nfrom ndcctools.taskvine.task import Task\n\n# Initialize the manager\nmanager = Manager(port=9123, name=\"compile_and_test_project\", shutdown=True, run_info_path=None, staging_path=None, ssl=None, init_fn=None, status_display_interval=None)\n\n# Enable resource monitoring\nmanager.enable_monitoring(watchdog=0, time_series=1)\n\n# Create a task to compile and test the project\ntask = Task(command=\"make all && make test\", task_info={})\n\n# Set resource limits\ntask.set_cores(4)\ntask.set_memory(1024)\ntask.set_disk(2048)\n\n# Add the project directory as input\ntask.add_input(manager.declare_file(\"complex_project/\", cache=False, peer_transfer=True, unlink_when_done=False), \"complex_project\", strict_input=True)\n\n# Submit the task\nmanager.submit(task)\n\n# Wait for the task to complete\ncompleted_task = manager.wait(timeout=\"wait_forever\")\n\n# Print the task's exit code and standard output\nprint(\"Exit Code:\", completed_task.exit_code())\nprint(\"Standard Output:\", completed_task.std_output())\n\n# Check for resource overuse and print details\nif completed_task.limits_exceeded():\n    for resource, overuse in completed_task.limits_exceeded().items():\n        print(f\"Resource {resource} overused by {overuse} units.\")\n```"
        },
        {
            "id": "taskvine6",
            "content": "Write a Python TaskVine application that executes multiple programs with different levels of resource requirements. The two task categories must be named \"intensive\" and \"light\". The \"intensive\" tasks require 8 cores and 16 GB of memory. The \"light\" tasks require 1 core and 2 GB of memory. In the intensive category, submit 10 tasks to execute the shell script \"intensive.sh\". In the light category, submit 100 tasks to execute the shell script \"light.sh\" Print the standard output of each task upon completion.",
            "response": "```python\nimport ndcctools.taskvine as vine\n\n# Create a manager\nmanager = vine.Manager(port=9123, name=\"resource_management\", shutdown=True)\n\n# Set resource requirements for categories\nmanager.set_category_resources_max(\"intensive\", {'cores': 8, 'memory': 16384})\nmanager.set_category_resources_max(\"light\", {'cores': 1, 'memory': 2048})\n\n# Submit intensive tasks\nfor i in range(10):\n    task = vine.Task(command=\"bash intensive.sh\")\n    task.set_category(\"intensive\")\n    manager.submit(task)\n\n# Submit light tasks\nfor i in range(100):\n    task = vine.Task(command=\"bash light.sh\")\n    task.set_category(\"light\")\n    manager.submit(task)\n\n# Wait for tasks to complete and print their output\nwhile not manager.empty():\n    completed_task = manager.wait(5)\n    if completed_task:\n        print(f\"Task {completed_task.id()} completed with output:\")\n        print(completed_task.output())\n```\n"
        },
        {
            "id": "taskvine7",
            "content": "Write a Python TaskVine application to perform matrix inversion and transposition. The matrix computations must be defined in Python functions and added to a TaskVine library called \"matrix_library\". The user must specify the size, m x n,  of the matrix and the number of matrices, i, on which to perform computation. The application must randomly generate i matrices and for each matrix, print the matrix, print the inverse matrix, and print the transposed matrix.",
            "response": "```python\nimport numpy as np\nfrom ndcctools.taskvine.manager import Manager\nfrom ndcctools.taskvine.task import FunctionCall\n\n# Define matrix operations\ndef invert_matrix(matrix):\n    return np.linalg.inv(matrix)\n\ndef transpose_matrix(matrix):\n    return np.transpose(matrix)\n\n# Main function\ndef main(matrix_size, num_matrices):\n    # Create a TaskVine manager\n    manager = Manager(port=0, name=\"matrix_operations\", shutdown=True)\n\n    # Create a library from the matrix functions\n    manager.create_library_from_functions(\n        library_name=\"matrix_library\",\n        function_list=[invert_matrix, transpose_matrix],\n        poncho_env=None,\n        init_command=None,\n        add_env=False,\n        hoisting_modules=[],\n        exec_mode='direct',\n        library_context_info=None\n    )\n\n    # Generate random matrices and perform operations\n    for _ in range(num_matrices):\n        matrix = np.random.rand(matrix_size[0], matrix_size[1])\n        print(\"Original Matrix:\\n\", matrix)\n\n        # Create tasks for inversion and transposition\n        invert_task = FunctionCall(\"matrix_library\", \"invert_matrix\", args=(matrix,), kwargs={})\n        transpose_task = FunctionCall(\"matrix_library\", \"transpose_matrix\", args=(matrix,), kwargs={})\n\n        # Submit tasks to the manager\n        manager.submit(invert_task)\n        manager.submit(transpose_task)\n\n        # Wait for tasks to complete and get results\n        invert_result = manager.wait_for_task_id(invert_task.id(), timeout=\"wait_forever\").output()\n        transpose_result = manager.wait_for_task_id(transpose_task.id(), timeout=\"wait_forever\").output()\n\n        # Print results\n        print(\"Inverted Matrix:\\n\", invert_result)\n        print(\"Transposed Matrix:\\n\", transpose_result)\n\n    # Shutdown the manager\n    manager.shutdown()\n\n# Example usage\nif __name__ == \"__main__\":\n    matrix_size = (3, 3)  # Example size\n    num_matrices = 2      # Example number of matrices\n    main(matrix_size, num_matrices)\n```\n\nThis code defines two functions for matrix inversion and transposition, creates a TaskVine manager, and uses it to perform these operations on randomly generated matrices. The results are printed for each matrix. Adjust `matrix_size` and `num_matrices` as needed."
        },
        {
            "id": "taskvine8",
            "content": "Write a Python Taskvine application to fetch the titles of multiple news webpages. The webpage contents must be downloaded asynchronously using the TaskVine futures executor. Print the URL and title of each webpage in order of the completion of each task. The webpages I am interested in are \"https://abcnews.com\", \"https://apnews.com\", \"https://axios.com\", \"https://cnn.com\", \"https://nbcnews.com\", \"https://nytimes.com\", \"https://reuters.com\", \"https://washingtonpost.com\", \"https://wsj.com\".",
            "response": "```python\nimport ndcctools.taskvine as vine\nimport requests\nfrom bs4 import BeautifulSoup\n\n# Function to fetch the title of a webpage\ndef fetch_title(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        return soup.title.string if soup.title else 'No title found'\n    except Exception as e:\n        return f\"Error fetching {url}: {str(e)}\"\n\n# List of URLs to fetch\nurls = [\n    \"https://abcnews.com\",\n    \"https://apnews.com\",\n    \"https://axios.com\",\n    \"https://cnn.com\",\n    \"https://nbcnews.com\",\n    \"https://nytimes.com\",\n    \"https://reuters.com\",\n    \"https://washingtonpost.com\",\n    \"https://wsj.com\"\n]\n\n# Create a TaskVine manager\nmanager = vine.Manager(port=0, name=\"news-title-fetcher\", shutdown=True)\n\n# Use TaskVine's map function to fetch titles asynchronously\nfutures = manager.map(fetch_title, urls, chunksize=1)\n\n# Wait for each task to complete and print the result\nfor future in futures:\n    result = future.output()\n    print(f\"URL: {urls[futures.index(future)]}, Title: {result}\")\n\n# Shutdown the manager\nmanager.shutdown()\n```"
        },
        {
            "id": "taskvine9",
            "content": "Write a Python TaskVine application to get the current date on a worker machine. The date must be stored to an output file named \"current_date\". To prevent an unwanted worker from connecting to the manager, use the password stored in the file \"taskvine.password\". Further, encrypt communication between the manager and worker with SSL using the \"key.pem\" and \"certificate.pem\" files.",
            "response": "```python\nfrom ndcctools.taskvine.manager import Manager\nfrom ndcctools.taskvine.task import Task\n\n# Initialize the manager with SSL and password\nmanager = Manager(\n    port=9123,\n    name=\"date_task\",\n    shutdown=True,\n    run_info_path=None,\n    staging_path=None,\n    ssl=(\"key.pem\", \"certificate.pem\"),\n    init_fn=None,\n    status_display_interval=None\n)\n\n# Set the password for worker authentication\nmanager.set_password_file(\"taskvine.password\")\n\n# Create a task to get the current date\ntask = Task(command=\"date > current_date\", task_info={})\n\n# Submit the task to the manager\nmanager.submit(task)\n\n# Wait for the task to complete\ncompleted_task = manager.wait(timeout=\"wait_forever\")\n\n# Check if the task completed successfully\nif completed_task and completed_task.successful():\n    print(\"Task completed successfully. The current date is stored in 'current_date'.\")\nelse:\n    print(\"Task failed.\")\n\n# Shutdown the manager\nmanager.cancel_all()\n```"
        }
    ]
}
